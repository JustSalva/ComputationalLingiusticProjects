2. Words and POS Tags statistics
    how many word/TAG tokens and how many sentences?
    dumas_train:
        numberOfLines: 80244
        numberOfTokens: 1595392
    dumas_test:
        numberOfLines: 200
        numberOfTokens: 3111

    per sostituire tags:
        cat dataSets/dumas_train | python Words_and_POS_Tags_statistics/replaceTaggedWordTokens.py > dumas_train_replaced
        cat dataSets/dumas_test | python Words_and_POS_Tags_statistics/replaceTaggedWordTokens.py > dumas_test_replaced
        N.B. if an import error is shown just write in the terminal "export PYTHONPATH='.'" before launching the commands
    per costruire nuovi files:
        launch restrictedLexiconBuilder

    restricted lexicon size = 10640

    10 most frequent words in train and tag frequencies:
        (launch countFrequentWordsAndTagFrequencies.py)
        see "dataSets/mostFrequentWords" and "dataSets/POS_tagSet_train" files

3. Baseline tagger
    Words associated to a single POStag: 7367
    Words associated to 2 POStags: 2530
    Words associated to 3 POStags: 658
    Words associated to 4 or more POStags: 86
    "start" statistics: ('start', [('VB', 45), ('NN', 26), ('VBP', 5)])
    Word with max number of tags: (('<UNK>', [('NN', 6555), ('NNS', 3737), ('JJ', 3425), ('VBG', 1458), ('VB', 1145), ('VBN', 1049), ('RB', 922), ('VBD', 705), ('VBZ', 703), ('VBP', 224), ('FW', 176), ('JJS', 120), ('JJR', 70), ('IN', 31), ('SYM', 11), ('UH', 8), ('MD', 5), ('DT', 5), ('PRP', 4), ('WP', 3), ('PRP$', 3), ('WDT', 3), ('LS', 2), ('RBR', 2), ('CC', 2), ('$', 1), ('-LRB-', 1), ('-RRB-', 1)]), 28)
        (sono 28)

    By Fabio:
     The expectation of test error rate per TAG is 1-((#W_1 + #W_2/2 + #W_3/3 + ...)/#W), where
     #W_n is the number of words which correspond to n tags with their frequencies (i.e. not
     distinct words). We can make this expectation supposing that for each word the frequence for
     each tag is the same (i.e. the winner tag wins for just one more iteration than the others).
     This is the worst assumption for tag assignment because it is the one with highest randomness,
     then this should be un upper bound for the error rate, but if we lose the assumption that test
     tagging is identical to training one, error can increase. Moreover we limit ourselves to 4 tags
     maximum, then our error supposition is still bigger. Anyway with data we got, the error should be
     1-[(1001112 + 396238/2 + 144246/3 + 53796/4)/(1001112+396238+144246+53796)]=0.209748
     Surely it is an high value.
     TO DO: Run the tagger and study the error on the training set to see the performance.
     1. Expected test error rate: 0.209748
     1. Actual training error rate: 0.052648
     4. Actual test error rate: 0.0498232
     We can see that our test error rate is definitely lower than our expected one, that is a nice
     since it was a strong upper bound to its value.

     5. Test error rate for tag RB is 0.171875, it is mainly confused with tags IN (7 times,
     relative 0.05469) and NN (6 times, relative 0.046875)
     6. Test error rate for tag VBN is 0.384615, it is mainly confused with tags VBD (19 times,
     relative 0.2923) and NN (4 times, relative 0.061538)


4.
    first run of crossvalidation
    optimal epsilonA: 0.5
    optimal epsilonB: 0.05
    train error rate = 0.07011192233632862
NB to install hmms:
    python -m pip install numpy cython
    python -m pip install hmms
    if you encounter problems: https://github.com/lopatovsky/HMMs/issues/4, in particular:
        python3.6 -m pip uninstall cython
        python3.6 -m pip install cython==0.25.2
        python3.6 -m pip install hmms
